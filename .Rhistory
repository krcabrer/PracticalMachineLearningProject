model2 <- train(diagnosis ~ ., data=selection2,method="glm")
testM2 <- predict(model2,testing)
testM2
confusionMatriz(testing$diangosis,predict(model2,testM2))
confusionMatrix(testing$diangosis,predict(model2,testM2))
model2 <- train(diagnosis ~ ., data=selectiontrain,method="glm")
selectiontrain <- training[c("diagnosis",names(training)[str_detect(names(training),"^IL")])]
selectiontest <- testing[c("diagnosis",names(testing)[str_detect(names(testing),"^IL")])]
model2 <- train(diagnosis ~ ., data=selectiontrain,method="glm")
testM2 <- predict(model2,selectiontest)
confusionMatrix(selectiontest$diangosis,predict(model2,testM2))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
selectiontrain <- training[c("diagnosis",names(training)[str_detect(names(training),"^IL")])]
selectiontest <- testing[c("diagnosis",names(testing)[str_detect(names(testing),"^IL")])]
model2 <- train(diagnosis ~ ., data=selectiontrain,method="glm")
testM2 <- predict(model2,selectiontest)
confusionMatrix(selectiontest$diagosis,predict(model2,testM2))
confusionMatrix(selectiontest$diagnosis,predict(model2,testM2))
selectiontest$diagnosis
predict(model2,testM2)
confusionMatrix(selectiontest$diagnosis,predict(model2,selectintest))
confusionMatrix(selectiontest$diagnosis,predict(model2,selectiontest))
preProc <- preProcess(selectiontrain,method="pca",thresh=0.8)
preProc <- preProcess(selectiontrain[,-1],method="pca",thresh=0.8)
trainPC <- predict(preProc,selectiontrain[,-1])
model1<-train(diagnosis ~ ., data=selectiontrain,method="glm",data=trainPC)
model1<-train(diagnosis ~ .,method="glm",data=trainPC)
model1<-train(selectiontrain$diagnosis ~ .,method="glm",data=trainPC)
model1
confusionMatrix(selectiontest$diagnosis,predict(model1,selectiontest))
selectiontest
preProc <- preProcess(selectiontrain[,-1],method="pca",thresh=0.8)
trainPC <- predict(preProc,selectiontrain[,-1])
model1<-train(selectiontrain$diagnosis ~ .,method="glm",data=trainPC)
confusionMatrix(selectiontest$diagnosis,predict(model1,selectiontest))
confusionMatrix(selectiontest$diagnosis,predict(model1,proProc))
confusionMatrix(selectiontest$diagnosis,predict(model1,preProc))
confusionMatrix(selectiontest$diagnosis,predict(model1,trainPC))
preProc <- preProcess(selectiontrain[,-1],method="pca",thresh=0.8)
trainPC <- predict(preProc,selectiontrain[,-1])
model1<-train(selectiontrain$diagnosis ~ .,method="glm",data=trainPC)
testPC <- predict(proProc,selectiontest[,-1])
testPC <- predict(preProc,selectiontest[,-1])
confusionMatrix(selectiontest$diagnosis,predict(model1,testPC))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
selectiontrain <- training[c("diagnosis",names(training)[str_detect(names(training),"^IL")])]
selectiontest <- testing[c("diagnosis",names(testing)[str_detect(names(testing),"^IL")])]
preProc <- preProcess(selectiontrain[,-1],method="pca",thresh=0.8)
trainPC <- predict(preProc,selectiontrain[,-1])
model1<-train(selectiontrain$diagnosis ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,selectiontest[,-1])
confusionMatrix(selectiontest$diagnosis,predict(model1,testPC))
model2 <- train(diagnosis ~ ., data=selectiontrain,method="glm")
confusionMatrix(selectiontest$diagnosis,predict(model2,selectiontest))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
selectiontrain <- training[c("diagnosis",names(training)[str_detect(names(training),"^IL")])]
selectiontest <- testing[c("diagnosis",names(testing)[str_detect(names(testing),"^IL")])]
preProc <- preProcess(selectiontrain[,-1],method="pca",thresh=0.8)
trainPC <- predict(preProc,selectiontrain[,-1])
model1<-train(selectiontrain$diagnosis ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,selectiontest[,-1])
confusionMatrix(selectiontest$diagnosis,predict(model1,testPC))
model2 <- train(diagnosis ~ ., data=selectiontrain,method="glm")
confusionMatrix(selectiontest$diagnosis,predict(model2,selectiontest))
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
require(stringr)
selection <- training[names(training)[str_detect(names(training),"^IL")]]
preProcess(selection,method="pca",thresh=.80)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
selectiontrain <- training[c("diagnosis",names(training)[str_detect(names(training),"^IL")])]
selectiontest <- testing[c("diagnosis",names(testing)[str_detect(names(testing),"^IL")])]
model2 <- train(diagnosis ~ ., data=selectiontrain,method="glm")
confusionMatrix(selectiontest$diagnosis,predict(model2,selectiontest))
preProc <- preProcess(selectiontrain[,-1],method="pca",thresh=0.8)
trainPC <- predict(preProc,selectiontrain[,-1])
model1<-train(selectiontrain$diagnosis ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,selectiontest[,-1])
confusionMatrix(selectiontest$diagnosis,predict(model1,testPC))
require(MySQL)
require(RMySQL)
ucscDb <- dbConnect(MySQL(), user = "genome",
host = "genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb, "show databases;")
dbDisconnect(ucscDb)
result
hg19 <- dbConnect(MySQL(),user = "genome", db="hg19",
host = "genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19,"affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fecth(query)
affyMis <- fetch(query)
quantile(affyMis$misMatches)
affyMisSmall <- fetch(query, n = 10)
dbClearResult(query)
dim(affyMisSmall)
dbDisconnect(hg19)
oauth_endpoints("github")
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. Register an application at https://github.com/settings/applications;
#    Use any URL you would like for the homepage URL (http://github.com is fine)
#    and http://localhost:1410 as the callback url
#
#    Insert your client ID and secret below - if secret is omitted, it will
#    look it up in the GITHUB_CONSUMER_SECRET environmental variable.
myapp <- oauth_app("github", "56b637a5baffac62cad9")
require(quantmod)
amzn <- getSymbols("AMZN",auto.assign=FALSE)
sampleTimes <- index(amzn)
summary(amzn)
plot(amzn)
plot(amzn)
amzn <- getSymbols("AMZN",auto.assign=FALSE)
sampleTimes <- index(amzn)
plot(amzn)
amzn$Index
str(amzn)
amzn$updated
names(amzn)
amzn$updated
attr(amzn,"updated")
head(amzn)
row.names(amzn)
rownames(amzn)
amzn
head(amzn)
date(amzn)
dates(amzn)
Dates(amzn)
as.Dates(amzn)
as.Date(amzn)
plot(amzn)
amzn$Data
attr(amzn,"Data")
class(amzn)
help(xts)
attr(amzn,"descr")
xtsAttributes(amzn)
head(amzn)
tail(amzn)
amzn[1,]
row.names(amzn)
dates(amzn)
date(amzn)
help(quantmod)
Op(amzn)
head(Op(amzn))
help(xts)
help(zoo)
date(amzn)
zoo(amzn)
head(zoo(amzn))
head(t.zoo(amzn))
head(t(amzn))
head(time(amzn))
time(amzn)
table(format(time(amzn),"%Y"))
idx<-format(time(amzn),"%Y")==2012
dates <- time(amzn)
dates <- time(amzn)
table(format(dates,"%Y"))
format(dates,"%Y")==2012
dates[format(dates,"%Y")==2012]
wday(dates[format(dates,"%Y")==2012])
require(lubridate)
wday(dates[format(dates,"%Y")==2012])
help(wday)
wday(dates[format(dates,"%Y")==2012],label=TRUE)
table(wday(dates[format(dates,"%Y")==2012],label=TRUE))
require(lubridate)
table(wday(dates[format(dates,"%Y")==2012],label=TRUE))
table(format(dates,"%Y"))
require(quantmod)
amzn <- getSymbols("AMZN",auto.assign=FALSE)
sampleTimes <- index(amzn)
plot(amzn)
dates <- time(amzn)
table(format(dates,"%Y"))
require(lubridate)
table(wday(dates[format(dates,"%Y")==2012],label=TRUE))
#------------------------------------------------------------------------------#
# Getting and Cleaning Data
# Course Project
# By Kenneth Cabrera
#------------------------------------------------------------------------------#
# Set path constants according to the .zip structure of the data.
path <- "UCI HAR Dataset"
pathTrain <- "train"
pathTest <- "test"
# Read the main files that contains the activity labels and the
# names of the features
activityLabels <- read.table(paste(".",path,"activity_labels.txt",sep="/"))
features <- read.table(paste(".",path,"features.txt",sep="/"))
# Read de data of the test set.
subj_test <- read.table(paste(".",path,pathTest,"subject_test.txt",sep="/"))
X_test <- read.table(paste(".",path,pathTest,"X_test.txt",sep="/"))
y_test <- read.table(paste(".",path,pathTest,"y_test.txt",sep="/"))
# Read de data of the train set.
subj_train <- read.table(paste(".",path,pathTrain,"subject_train.txt",sep="/"))
X_train <- read.table(paste(".",path,pathTrain,"X_train.txt",sep="/"))
y_train <- read.table(paste(".",path,pathTrain,"y_train.txt",sep="/"))
#------------------------------------------------------------------------------#
# 1. Merges the training and the test sets to create one data set.
#------------------------------------------------------------------------------#
# Combine the whole data for the train set.
X_trainT <- cbind(subject = subj_train$V1, activity = y_train$V1, X_train)
# Combine the whole data for the test set.
X_testT  <- cbind(subject = subj_test$V1,  activity = y_test$V1,  X_test )
# Combine the train set and the test set to a unifiy set.
X_total <- rbind(X_trainT,X_testT)
# Take the variable names and change them to be a valid variable name in R.
varNames <- gsub("[()]","",features$V2)
varNames <- gsub("[,-]","_",varNames)
# Set the names of this variables to the whole dataset.
names(X_total)[1:(length(varNames))+2] <- varNames
# The activity names to lower case (are easier to read)
labelActivity <- tolower(as.character(activityLabels$V2))
# Function that change the firs letter of each word in upcase.
# A slight modification of the same function in help(tolower) example.
.simpleCap <- function(x) {
s <- strsplit(x, "[_ ]")[[1]]
paste(toupper(substring(s, 1, 1)), substring(s, 2),
sep = "", collapse = " ")
}
# Appling this function to the label for the activities.
labelActivity <- as.vector(sapply(labelActivity,.simpleCap))
# Put the labels to the activity in a factor variable.
X_total$activity <- factor(X_total$activity,
labels = labelActivity)
# Show three records of this unify dataset.
head(X_total,3)
#------------------------------------------------------------------------------#
# 2. Extracts only the measurements on the mean and
# standard deviation for each measurement.
#------------------------------------------------------------------------------#
require(stringr)
selectVars <- c(TRUE,TRUE,str_detect(features$V2,"mean\\(\\)|std\\(\\)"))
X_sel <- X_total[selectVars]
require(reshape2)
X_melt <- melt(X_sel,c("subject","activity"))
X_melt$typeVar <- str_extract(X_melt$variable,"mean|std")
X_melt$VarName <- str_replace(X_melt$variable,"_mean_|_std_|_std|_mean","")
X_melt["variable"]<-NULL
setwd("~/Dropbox/sem201402/personal/gettingandCleaningDataCourseII/project")
#------------------------------------------------------------------------------#
# Getting and Cleaning Data
# Course Project
# By Kenneth Cabrera
#------------------------------------------------------------------------------#
# Set path constants according to the .zip structure of the data.
path <- "UCI HAR Dataset"
pathTrain <- "train"
pathTest <- "test"
# Read the main files that contains the activity labels and the
# names of the features
activityLabels <- read.table(paste(".",path,"activity_labels.txt",sep="/"))
features <- read.table(paste(".",path,"features.txt",sep="/"))
# Read de data of the test set.
subj_test <- read.table(paste(".",path,pathTest,"subject_test.txt",sep="/"))
X_test <- read.table(paste(".",path,pathTest,"X_test.txt",sep="/"))
y_test <- read.table(paste(".",path,pathTest,"y_test.txt",sep="/"))
# Read de data of the train set.
subj_train <- read.table(paste(".",path,pathTrain,"subject_train.txt",sep="/"))
X_train <- read.table(paste(".",path,pathTrain,"X_train.txt",sep="/"))
y_train <- read.table(paste(".",path,pathTrain,"y_train.txt",sep="/"))
#------------------------------------------------------------------------------#
# 1. Merges the training and the test sets to create one data set.
#------------------------------------------------------------------------------#
# Combine the whole data for the train set.
X_trainT <- cbind(subject = subj_train$V1, activity = y_train$V1, X_train)
# Combine the whole data for the test set.
X_testT  <- cbind(subject = subj_test$V1,  activity = y_test$V1,  X_test )
# Combine the train set and the test set to a unifiy set.
X_total <- rbind(X_trainT,X_testT)
# Take the variable names and change them to be a valid variable name in R.
varNames <- gsub("[()]","",features$V2)
varNames <- gsub("[,-]","_",varNames)
# Set the names of this variables to the whole dataset.
names(X_total)[1:(length(varNames))+2] <- varNames
# The activity names to lower case (are easier to read)
labelActivity <- tolower(as.character(activityLabels$V2))
# Function that change the firs letter of each word in upcase.
# A slight modification of the same function in help(tolower) example.
.simpleCap <- function(x) {
s <- strsplit(x, "[_ ]")[[1]]
paste(toupper(substring(s, 1, 1)), substring(s, 2),
sep = "", collapse = " ")
}
# Appling this function to the label for the activities.
labelActivity <- as.vector(sapply(labelActivity,.simpleCap))
# Put the labels to the activity in a factor variable.
X_total$activity <- factor(X_total$activity,
labels = labelActivity)
# Show three records of this unify dataset.
head(X_total,3)
#------------------------------------------------------------------------------#
# 2. Extracts only the measurements on the mean and
# standard deviation for each measurement.
#------------------------------------------------------------------------------#
require(stringr)
selectVars <- c(TRUE,TRUE,str_detect(features$V2,"mean\\(\\)|std\\(\\)"))
X_sel <- X_total[selectVars]
require(reshape2)
X_melt <- melt(X_sel,c("subject","activity"))
X_melt$typeVar <- str_extract(X_melt$variable,"mean|std")
X_melt$VarName <- str_replace(X_melt$variable,"_mean_|_std_|_std|_mean","")
X_melt["variable"]<-NULL
head(X_melt)
X_last <- dcast(X_melt,subject+ activity + typeVar  ~ VarName)
head(X_last)
X_last <- dcast(X_melt,subject+ activity + typeVar  ~ VarName, mean)
head(X_last)
with(X_last,table(subject))
with(X_last,table(subject,activity))
head(X_melt)
X_last <- dcast(X_melt,subject+ activity + typeVar  ~ VarName, mean)
head(X_last)
#------------------------------------------------------------------------------#
# Getting and Cleaning Data
# Course Project
# By Kenneth Cabrera
#------------------------------------------------------------------------------#
# Set path constants according to the .zip structure of the data.
path <- "UCI HAR Dataset"
pathTrain <- "train"
pathTest <- "test"
# Read the main files that contains the activity labels and the
# names of the features
activityLabels <- read.table(paste(".",path,"activity_labels.txt",sep="/"))
features <- read.table(paste(".",path,"features.txt",sep="/"))
# Read de data of the test set.
subj_test <- read.table(paste(".",path,pathTest,"subject_test.txt",sep="/"))
X_test <- read.table(paste(".",path,pathTest,"X_test.txt",sep="/"))
y_test <- read.table(paste(".",path,pathTest,"y_test.txt",sep="/"))
# Read de data of the train set.
subj_train <- read.table(paste(".",path,pathTrain,"subject_train.txt",sep="/"))
X_train <- read.table(paste(".",path,pathTrain,"X_train.txt",sep="/"))
y_train <- read.table(paste(".",path,pathTrain,"y_train.txt",sep="/"))
#------------------------------------------------------------------------------#
# 1. Merges the training and the test sets to create one data set.
#------------------------------------------------------------------------------#
# Combine the whole data for the train set.
X_trainT <- cbind(subject = subj_train$V1, activity = y_train$V1, X_train)
# Combine the whole data for the test set.
X_testT  <- cbind(subject = subj_test$V1,  activity = y_test$V1,  X_test )
# Combine the train set and the test set to a unifiy set.
X_total <- rbind(X_trainT,X_testT)
# Take the variable names and change them to be a valid variable name in R.
varNames <- gsub("[()]","",features$V2)
varNames <- gsub("[,-]","_",varNames)
# Set the names of this variables to the whole dataset.
names(X_total)[1:(length(varNames))+2] <- varNames
# The activity names to lower case (are easier to read)
labelActivity <- tolower(as.character(activityLabels$V2))
# Function that change the firs letter of each word in upcase.
# A slight modification of the same function in help(tolower) example.
.simpleCap <- function(x) {
s <- strsplit(x, "[_ ]")[[1]]
paste(toupper(substring(s, 1, 1)), substring(s, 2),
sep = "", collapse = " ")
}
# Appling this function to the label for the activities.
labelActivity <- as.vector(sapply(labelActivity,.simpleCap))
# Put the labels to the activity in a factor variable.
X_total$activity <- factor(X_total$activity,
labels = labelActivity)
# Show three records of this unify dataset.
head(X_total,3)
#------------------------------------------------------------------------------#
# 2. Extracts only the measurements on the mean and
# standard deviation for each measurement.
#------------------------------------------------------------------------------#
require(stringr)
selectVars <- c(TRUE,TRUE,str_detect(features$V2,"mean\\(\\)|std\\(\\)"))
X_sel <- X_total[selectVars]
require(reshape2)
X_melt <- melt(X_sel,c("subject","activity"))
X_melt$typeVar <- str_extract(X_melt$variable,"mean|std")
X_melt$VarName <- str_replace(X_melt$variable,"_mean_|_std_|_std|_mean","")
X_melt["variable"]<-NULL
head(X_melt)
X_last <- dcast(X_melt,subject+ activity  ~ VarName + typeVar)
help(X_metl)
help(X_melt)
head(X_melt)
summary(X_melt)
names(X_melt)
source('~/Dropbox/sem201402/personal/gettingandCleaningDataCourseII/project/run_analysis.R', echo=TRUE)
summary(X_melt)
with(X_melt, length(levels(VarName)))
with(X_melt, length(levels(VarName) * length(levels(typeVar))))
with(X_melt, length(levels(VarName)) * length(levels(typeVar)))
with(X_melt, length(levels(VarName)) * length(levels(typeVar)) * length(levels(activity)))
with(X_melt, length(levels(VarName)) * length(levels(typeVar)) * length(levels(activity)) * length(unique(subject)))
with(X_melt, length(levels(VarName)) * length(levels(typeVar)) * length(levels(activity)) * length(unique(subject))) -> x
x
dim(X_melt)/x
dim(X_melt)[1]/x
source('~/Dropbox/sem201402/personal/gettingandCleaningDataCourseII/project/run_analysis.R', echo=TRUE)
head(X_test)
dim(X_test)
dim(X_trainT)
names(X_trainT)
head(X_trainT)
dim(X_total)
names(X_total)[1:10]
with(X_total,unique(subject))
length(with(X_total,unique(subject)))
source('~/.active-rstudio-document', echo=TRUE)
with(dataHumActivityTidy,levels(VarName))
source('~/Dropbox/sem201402/personal/gettingandCleaningDataCourseII/project/run_analysis.R', echo=TRUE)
size(HumActDta)
sizeof(HumActDta)
object.size(HumActDta)
object.size(HumActDta)/2^10
2^10
levels(HumActDtaTidy$activity)
names(HumActDtaTidy)
HumActDtaTidy2 <- droplevels(subset(HumActDtaTidy, typeVar=="mean"))
head(HumActDtaTidy2)
HumActDtaTidy2$typeVar <- NULL
head(HumActDtaTidy2)
HumActDtaTidy2sum <- aggregate(subset(HumActDtaTidy2,select=value),
with(HumActDtaTidy2,
list(suject=subject,
activity=activity,
VarName=VarName)),
mean)
head(HumActDtaTidy2sum)
help(aggregate)
with(HumActDtaTidy2sum,length(unique(subject)))
with(HumActDtaTidy2sum,length(unique(suject)))
source('~/Dropbox/sem201402/personal/gettingandCleaningDataCourseII/project/run_analysis.R', echo=TRUE)
with(HumActDataTidy2sum)
with(HumActDtaTidy2sum,length(unique(subject)))
with(HumActDtaTidy2sum,length(unique(activity)))
with(HumActDtaTidy2sum,length(unique(VarName)))
30*6*33
nrows(HumActDtaTidy2sum)
rows(HumActDtaTidy2sum)
nrow(HumActDtaTidy2sum)
nrow(HumActDtaTidy2sum)
write.table(HumActDtaTidy2sum,"HumanActivityDataSumarize.txt",
row.names=FALSE)
source('~/Dropbox/sem201402/personal/gettingandCleaningDataCourseII/project/run_analysis.R', echo=TRUE)
head(HumActDtaTidy2sum)
dcast(HumActDtaTidy2sum)
help(dcast)
dcast(HumActDtaTidy2sum, subject + activity ~ VarName) -> temp1
head(temp1)
head(HumActDtaTidy2)
HumActDtaTidy3 <- dcast(HumActDtaTidy2, subject + activity ~ VarName, mean)
HumActDtaTidy3 <- dcast(HumActDtaTidy2sum, subject + activity ~ VarName)
source('~/Dropbox/sem201402/personal/gettingandCleaningDataCourseII/project/run_analysis.R', echo=TRUE)
setwd("/media/sda1/Dropbox/sem201402/personal/gettingandCleaningDataCourseII/GetCleanDataCourseProject")
source('/media/sda1/Dropbox/sem201402/personal/gettingandCleaningDataCourseII/GetCleanDataCourseProject/run_analysis.R', echo=TRUE)
source('~/Dropbox/sem201402/personal/gettingandCleaningDataCourseII/GetCleanDataCourseProject/run_analysis.R', echo=TRUE)
names(HumActDtaTidy3)
data.frame(names(HumActDtaTidy3))
levels(HumActDtaTidy3$activity)
varNames
features$V2
title: "How to predict a good or bad barbell lifts"
setwd("/media/sda1/Dropbox/sem201402/personal/practicalMachineLearningCourse/PracticalMachineLearningProject")
dir()
